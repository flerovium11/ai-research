{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train YOLO and a Segmentation Model for road markings on Images from self-generated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset by splitting video into frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "input('Are you sure you want to regenerate the frames? Press Enter to continue...')\n",
    "print()\n",
    "\n",
    "videos_path = 'data/traffic-signs-and-road-markings'\n",
    "video_names = ['video1.mp4', 'video2.mp4']\n",
    "sampling_rate = 20\n",
    "output_path = 'data/traffic-signs-and-road-markings/frames'\n",
    "\n",
    "if os.path.exists(output_path):\n",
    "    print('Deleting existing frames...')\n",
    "    for file_name in os.listdir(output_path):\n",
    "        os.remove(os.path.join(output_path, file_name))\n",
    "else:\n",
    "    print('Creating output directory...')\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "print('Extracting frames...')\n",
    "for video_name in video_names:\n",
    "    video_path = os.path.join(videos_path, video_name)\n",
    "    capture = cv2.VideoCapture(video_path)\n",
    "    fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    print(f'Video: {video_name}')\n",
    "    print(f'FPS: {fps}')\n",
    "    print(f'Size: {width}x{height}')\n",
    "\n",
    "    frame_count = 0\n",
    "    saved_frames = 0\n",
    "    while True:\n",
    "        success, frame = capture.read()\n",
    "        print(f'Saved frames: {saved_frames}', end='\\r')\n",
    "        if not success:\n",
    "            break\n",
    "        \n",
    "        if frame_count % sampling_rate == 0:\n",
    "            saved_frames += 1\n",
    "\n",
    "            # rotate frame 90 degrees\n",
    "            frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "            # crop frame to a centered square\n",
    "            min_dim = min(frame.shape[0], frame.shape[1])\n",
    "            start_x = (frame.shape[1] - min_dim) // 2\n",
    "            start_y = (frame.shape[0] - min_dim) // 2\n",
    "            frame = frame[start_y:start_y+min_dim, start_x:start_x+min_dim]\n",
    "\n",
    "            # resize frame\n",
    "            frame = cv2.resize(frame, (512, 512))\n",
    "\n",
    "            # save frame\n",
    "            cv2.imwrite(os.path.join(output_path, f'{video_name.split('.')[0]}_{str(saved_frames).zfill(3)}.jpg'), frame)\n",
    "                \n",
    "        frame_count += 1\n",
    "    \n",
    "    print(f'Successfully saved {saved_frames} frames from video {video_name} ({frame_count} frames in total)')\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Localization classes: ['green-light', 'red-light', 'speed-limit-10', 'speed-limit-20', 'stop-sign']\n",
      "Segmentation classes: ['road', 'traffic-sign']\n",
      "['video1_1.jpg', 'video1_2.jpg', 'video1_3.jpg', 'video1_4.jpg', 'video1_5.jpg', 'video1_6.jpg', 'video1_7.jpg', 'video1_8.jpg', 'video1_9.jpg', 'video1_10.jpg', 'video1_11.jpg', 'video1_12.jpg', 'video1_13.jpg', 'video1_14.jpg', 'video1_15.jpg', 'video1_16.jpg', 'video1_17.jpg', 'video1_18.jpg', 'video1_19.jpg', 'video1_20.jpg', 'video1_21.jpg', 'video1_22.jpg', 'video1_23.jpg', 'video1_24.jpg', 'video1_25.jpg', 'video1_26.jpg', 'video1_27.jpg', 'video1_28.jpg', 'video1_29.jpg', 'video1_30.jpg', 'video1_31.jpg', 'video1_32.jpg', 'video1_33.jpg', 'video1_34.jpg', 'video1_35.jpg', 'video1_36.jpg', 'video1_37.jpg', 'video1_38.jpg', 'video2_1.jpg', 'video2_2.jpg', 'video2_3.jpg', 'video2_4.jpg', 'video2_5.jpg', 'video2_6.jpg', 'video2_7.jpg', 'video2_8.jpg', 'video2_9.jpg', 'video2_10.jpg', 'video2_11.jpg', 'video2_12.jpg', 'video2_13.jpg', 'video2_14.jpg', 'video2_15.jpg', 'video2_16.jpg', 'video2_17.jpg', 'video2_18.jpg', 'video2_19.jpg', 'video2_20.jpg', 'video2_21.jpg', 'video2_22.jpg', 'video2_23.jpg', 'video2_24.jpg', 'video2_25.jpg', 'video2_26.jpg', 'video2_27.jpg', 'video2_28.jpg', 'video2_29.jpg', 'video2_30.jpg', 'video2_31.jpg', 'video2_32.jpg', 'video2_33.jpg', 'video2_34.jpg', 'video2_35.jpg', 'video2_36.jpg', 'video2_37.jpg', 'video2_38.jpg', 'video2_39.jpg', 'video2_40.jpg', 'video2_41.jpg', 'video2_42.jpg', 'video2_43.jpg', 'video2_44.jpg', 'video2_45.jpg', 'video2_46.jpg', 'video2_47.jpg', 'video2_48.jpg', 'video2_49.jpg', 'video2_50.jpg', 'video2_51.jpg', 'video2_52.jpg', 'video2_53.jpg', 'video2_54.jpg', 'video2_55.jpg', 'video2_56.jpg', 'video2_57.jpg', 'video2_58.jpg', 'video2_59.jpg', 'video2_60.jpg', 'video2_61.jpg', 'video2_62.jpg', 'video2_63.jpg', 'video2_64.jpg', 'video2_65.jpg', 'video2_66.jpg', 'video2_67.jpg', 'video2_68.jpg', 'video2_69.jpg', 'video2_70.jpg', 'video2_71.jpg', 'video2_72.jpg', 'video2_73.jpg', 'video2_74.jpg', 'video2_75.jpg', 'video2_76.jpg', 'video2_77.jpg', 'video2_78.jpg', 'video2_79.jpg', 'video2_80.jpg', 'video2_81.jpg', 'video2_82.jpg', 'video2_83.jpg', 'video2_84.jpg', 'video2_85.jpg', 'video2_86.jpg', 'video2_87.jpg', 'video2_88.jpg', 'video2_89.jpg', 'video2_90.jpg', 'video2_91.jpg', 'video2_92.jpg', 'video2_93.jpg', 'video2_94.jpg', 'video2_95.jpg', 'video2_96.jpg', 'video2_97.jpg', 'video2_98.jpg', 'video2_99.jpg', 'video2_100.jpg', 'video2_101.jpg', 'video2_102.jpg', 'video2_103.jpg', 'video2_104.jpg', 'video2_105.jpg', 'video2_106.jpg', 'video2_107.jpg', 'video2_108.jpg', 'video2_109.jpg', 'video2_110.jpg', 'video2_111.jpg', 'video2_112.jpg', 'video2_113.jpg']\n",
      "Successfully loaded 151 data entries\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "dataset_path = 'data/traffic-signs-and-road-markings/sr-20-annotated'\n",
    "images_path = os.path.join(dataset_path, 'images')\n",
    "\n",
    "with open(os.path.join(dataset_path, 'localization-classes.txt'), 'r') as file:\n",
    "    localization_classes = file.read().splitlines()\n",
    "\n",
    "with open(os.path.join(dataset_path, 'segmentation-classes.txt'), 'r') as file:\n",
    "    segmentation_classes = file.read().splitlines()\n",
    "\n",
    "with open(os.path.join(dataset_path, 'localization-classes-german.txt'), 'r', encoding='utf-8') as file:\n",
    "    localization_classes_german = file.read().splitlines()\n",
    "\n",
    "with open(os.path.join(dataset_path, 'segmentation-classes-german.txt'), 'r', encoding='utf-8') as file:\n",
    "    segmentation_classes_german = file.read().splitlines()\n",
    "\n",
    "print('Localization classes:', localization_classes)\n",
    "print('Segmentation classes:', segmentation_classes)\n",
    "\n",
    "with open(os.path.join(dataset_path, 'localization.json'), 'r') as file:\n",
    "    localization_data_list = json.load(file)\n",
    "\n",
    "with open(os.path.join(dataset_path, 'segmentation.json'), 'r') as file:\n",
    "    segmentation_data_list = json.load(file)\n",
    "\n",
    "localization_data = {}\n",
    "for entry in localization_data_list:\n",
    "    image_name = entry['data']['image'].split('%5C')[-1]\n",
    "    localization_data[image_name] = entry\n",
    "\n",
    "segmentation_data = {}\n",
    "for entry in segmentation_data_list:\n",
    "    image_name = entry['data']['image'].split('%5C')[-1]\n",
    "    segmentation_data[image_name] = entry\n",
    "\n",
    "image_width = 512\n",
    "image_height = 512\n",
    "             \n",
    "data = []\n",
    "\n",
    "for image_name in os.listdir(images_path):\n",
    "    image_path = os.path.join(images_path, image_name)\n",
    "    image = plt.imread(image_path)\n",
    "    \n",
    "    if image.shape[0] != image_height or image.shape[1] != image_width:\n",
    "        print(f'Invalid image size: {image.shape} (expected: {image_height}x{image_width})')\n",
    "        continue\n",
    "    \n",
    "    localization = localization_data[image_name]\n",
    "    bounding_boxes = []\n",
    "    for annotation in localization['annotations']:\n",
    "        result = annotation['result']\n",
    "        if not result:\n",
    "            continue\n",
    "\n",
    "        for entry in result:\n",
    "            value = entry['value']\n",
    "            label = value['rectanglelabels'][0]\n",
    "            if label not in localization_classes:\n",
    "                print(f'Unknown localization class: {label}')\n",
    "                continue\n",
    "                \n",
    "            class_index = localization_classes.index(label)\n",
    "            x_center = (value['x'] + value['width'] / 2) / 100\n",
    "            y_center = (value['y'] + value['height'] / 2) / 100\n",
    "            width = value['width'] / 100\n",
    "            height = value['height'] / 100\n",
    "            bounding_boxes.append([class_index, x_center, y_center, width, height])\n",
    "\n",
    "    # create binary mask for each segmentation class from the polygon data\n",
    "    segmentation = segmentation_data[image_name]\n",
    "    masks = np.zeros((len(segmentation_classes), image_width, image_height), dtype=np.uint8)\n",
    "    for annotation in segmentation['annotations']:\n",
    "        result = annotation['result']\n",
    "        if not result:\n",
    "            continue\n",
    "\n",
    "        for entry in result:\n",
    "            value = entry['value']\n",
    "            label = value['polygonlabels'][0]\n",
    "            if label not in segmentation_classes:\n",
    "                print(f'Unknown segmentation class: {label}')\n",
    "                continue\n",
    "\n",
    "            class_index = segmentation_classes.index(label)\n",
    "            points = value['points']\n",
    "            # points are given as percentages of the image size\n",
    "            polygon = np.array([[int(p[0] / 100 * image_width), int(p[1] / 100 * image_height)] for p in points], dtype=np.int32)\n",
    "            cv2.fillPoly(masks[class_index], [polygon], 1)\n",
    "\n",
    "    data.append({\n",
    "        'name': image_name,\n",
    "        'image': image,\n",
    "        'bounding_boxes': bounding_boxes,\n",
    "        'segmentation_masks': masks\n",
    "    })\n",
    "\n",
    "# sort by frame because i had unlucky naming when labeling the data for the first time\n",
    "data.sort(key=lambda x: [int(n) if n.isdigit() else n for n in re.split(r'(\\d+)', x['name'])])\n",
    "\n",
    "print([d['name'] for d in data])\n",
    "print(f'Successfully loaded {len(data)} data entries')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved 151 frames\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.patches import Patch\n",
    "\n",
    "colors = [\n",
    "    [0.1, 0.2, 0.5],\n",
    "    [0.8, 0.1, 0.1],\n",
    "    [0.1, 0.6, 0.1],\n",
    "    [0.6, 0.1, 0.6],\n",
    "    [0.1, 0.6, 0.6],\n",
    "]\n",
    "\n",
    "def show_overlayed_masks(ax, masks):\n",
    "    surrounding_mask = np.ones((image_width, image_height), dtype=np.uint8)\n",
    "    for mask in masks:\n",
    "        surrounding_mask[mask == 1] = 0\n",
    "\n",
    "    display_masks = [*masks, surrounding_mask]\n",
    "    for i, mask in enumerate(display_masks):\n",
    "        overlay = np.zeros((image_width, image_height, 4))\n",
    "        overlay[mask == 1] = [*colors[i], 1]\n",
    "        ax.imshow(overlay, alpha=0.3)\n",
    "    \n",
    "    legend_elements = [\n",
    "        Patch(facecolor=[*colors[i], 0.6], label=[*segmentation_classes_german, 'Umgebung'][i]) for i in range(len(segmentation_classes) + 1)\n",
    "    ]\n",
    "\n",
    "    plt.legend(handles=legend_elements, loc='upper right', fontsize=6, title='Segmentierung', title_fontsize=8)\n",
    "\n",
    "def show_bounding_boxes(ax, bounding_boxes):\n",
    "    for box in bounding_boxes:\n",
    "        class_index, x_center, y_center, width, height = box\n",
    "        x = (x_center - width / 2) * image_width\n",
    "        y = (y_center - height / 2) * image_height\n",
    "        rect = plt.Rectangle((x, y), width * image_width, height * image_height, linewidth=1, edgecolor=colors[class_index], facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(x + 5, y - 10, localization_classes_german[class_index], color='white', backgroundcolor=[c * 0.5 for c in colors[class_index]], fontsize=6)       \n",
    "\n",
    "\n",
    "if os.path.exists('images/frames'):\n",
    "    for file_name in os.listdir('images/frames'):\n",
    "        os.remove(os.path.join('images/frames', file_name))\n",
    "else:\n",
    "    os.makedirs('images/frames', exist_ok=True)\n",
    "\n",
    "for i, entry in enumerate(data):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(entry['image'])\n",
    "    ax.axis('off')\n",
    "    show_overlayed_masks(ax, entry['segmentation_masks'])\n",
    "    show_bounding_boxes(ax, entry['bounding_boxes'])\n",
    "    plt.savefig(f'images/frames/frame_{i}.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "    print(f'Saved frame {i}/{len(data)}', end='\\r')\n",
    "\n",
    "print(f'Successfully saved {len(data)} frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved successfully\n"
     ]
    }
   ],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('images/video.mp4', fourcc, 2, (1000, 1000), True)\n",
    "for i in range(109):\n",
    "    img = cv2.imread(f'images/frames/frame_{i}.png')\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    img = cv2.resize(img, (1000, 1000))\n",
    "    out.write(img)\n",
    "out.release()\n",
    "print('Video saved successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train YOLO Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
