{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train different Neural Networks on a Traffic Sign Detection Dataset\n",
        "Thanks:\n",
        "\n",
        "- https://cs231n.github.io/neural-networks-3/#sanitycheck\n",
        "- https://www.analyticsvidhya.com/blog/2021/12/traffic-signs-recognition-using-cnn-and-keras-in-python/#h-cnn-model-building\n",
        "- https://medium.com/towards-data-science/8-simple-techniques-to-prevent-overfitting-4d443da2ef7d\n",
        "- https://www.youtube.com/watch?v=r0RspiLG260"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# global imports\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "import os\n",
        "from enum import Enum\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Optional\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Loading\n",
        "Load and select images from dataset folder, save images + annotations as entries in training, validation and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DataType(Enum):\n",
        "    TRAIN = 1\n",
        "    TEST = 2\n",
        "    VALID = 3\n",
        "\n",
        "class Label:\n",
        "    def __init__(self, raw_data: str) -> None:\n",
        "        split_data = raw_data.split(' ')\n",
        "        self.category = int(split_data[0])\n",
        "        self.center_x, self.center_y, self.width, self.height = map(float, split_data[1:])\n",
        "\n",
        "class Entry:\n",
        "    def __init__(self, image: np.array, labels: list[Label], image_name: str) -> None:\n",
        "        self.image = image\n",
        "        self.labels = labels\n",
        "        self.image_name = image_name\n",
        "\n",
        "\n",
        "dataset_path = 'data/traffic-signs-detection'\n",
        "info_file = os.path.join(dataset_path, 'car/data.yaml')\n",
        "categories = yaml.load(open(info_file), Loader=yaml.FullLoader)['names']\n",
        "\n",
        "# different setting depending on which task the model should have (single or multiclass, etc.)\n",
        "img_size = 32\n",
        "min_bounding_box_size = 0.5\n",
        "only_single_label = True\n",
        "forbidden_file_prefixes = ['FisheyeCamera', 'road']\n",
        "grayscale = False\n",
        "\n",
        "def load_image_data(type: DataType):\n",
        "    data_path = os.path.join(dataset_path, 'car', type.name.lower())\n",
        "    images_path = os.path.join(data_path, 'images')\n",
        "    labels_path = os.path.join(data_path, 'labels')\n",
        "\n",
        "    entries = []\n",
        "    files_in_folder = os.listdir(images_path)\n",
        "    print(f'Scanning {len(files_in_folder)} entries from {images_path} and {labels_path}...')\n",
        "\n",
        "    for image_name in files_in_folder:\n",
        "        image = plt.imread(os.path.join(images_path, image_name))\n",
        "        image = np.array(Image.fromarray(image).resize((img_size, img_size)))\n",
        "\n",
        "        if grayscale:\n",
        "            image = np.mean(image, axis=2)\n",
        "        \n",
        "        image = image / 255.0\n",
        "        labels_raw = open(os.path.join(labels_path, image_name.replace('.jpg', '.txt'))).read().split('\\n')\n",
        "        labels = [Label(label) for label in labels_raw if label]\n",
        "\n",
        "        if (\n",
        "            only_single_label and len(labels) > 1\n",
        "            or len(labels) == 0\n",
        "            or any([image_name.startswith(prefix) for prefix in forbidden_file_prefixes])\n",
        "            or any([label.width < min_bounding_box_size or label.height < min_bounding_box_size for label in labels])\n",
        "        ):\n",
        "            continue\n",
        "\n",
        "        entries.append(Entry(image, labels, image_name))\n",
        "\n",
        "    return entries\n",
        "\n",
        "train_data = load_image_data(DataType.TRAIN)\n",
        "validate_data = load_image_data(DataType.VALID)\n",
        "test_data = load_image_data(DataType.TEST)\n",
        "\n",
        "print(f'Loaded {len(train_data)} training images, {len(validate_data)} validation images and {len(test_data)} test images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Visualization\n",
        "Show random images and bounding boxes from loaded data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_images = 6\n",
        "categories_to_display = [0, 3, 13, 14]\n",
        "fig, axs = plt.subplots(len(categories_to_display), num_images, figsize=(num_images * 2, len(categories_to_display) * 2))\n",
        "print(f'Displaying {num_images} random images from each of the following categories: {\", \".join([categories[category] for category in categories_to_display])}')\n",
        "\n",
        "for idx, category in enumerate(categories_to_display):\n",
        "    category_entries = [entry for entry in validate_data if entry.labels[0].category == category]\n",
        "    \n",
        "    if len(category_entries) >= num_images:\n",
        "        selected_entries = random.sample(category_entries, num_images)\n",
        "    else:\n",
        "        selected_entries = category_entries\n",
        "    \n",
        "    for i, entry in enumerate(selected_entries):\n",
        "        axs[idx, i].imshow(entry.image, cmap='gray')\n",
        "        axs[idx, i].axis('off')\n",
        "        if i == 0:\n",
        "            axs[idx, i].set_title(categories[category])\n",
        "            \n",
        "        for label in entry.labels:\n",
        "            x = label.center_x * img_size\n",
        "            y = label.center_y * img_size\n",
        "            w = label.width * img_size\n",
        "            h = label.height * img_size\n",
        "            rect = plt.Rectangle((x - w / 2, y - h / 2), w, h, fill=False, color='r')\n",
        "            axs[idx, i].add_patch(rect)\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Utility functions\n",
        "Because we sorted specific images out while loading the data, the validation and test data should be changed to match the class distribution of the training images again.\n",
        "\n",
        "Additionally there is a helper function to split the data entries into images and labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_data(data: list[Entry]):\n",
        "    np.random.shuffle(data)\n",
        "    images = np.array([entry.image for entry in data])\n",
        "    labels = np.array([entry.labels[0].category for entry in data])\n",
        "    return images, labels\n",
        "\n",
        "def print_category_distribution(labels):\n",
        "    total = len(labels)\n",
        "    distribution = {category: np.sum(labels == category) / total * 100 for category in np.unique(labels)}\n",
        "    print(\", \".join([f'{categories[cat]}: {dist:.2f}%' for cat, dist in distribution.items()]))\n",
        "\n",
        "def get_balanced_data(source_data: list[Entry], target_distribution: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Resamples data to match a target distribution of categories.\n",
        "    \n",
        "    Args:\n",
        "        source_data: List of entries to be resampled\n",
        "        target_distribution: Array of target percentages for each category\n",
        "        \n",
        "    Returns:\n",
        "        Tuple of (images, labels) with the desired distribution\n",
        "    \"\"\"\n",
        "    # Get initial data\n",
        "    np.random.shuffle(source_data)\n",
        "    images = np.array([entry.image for entry in source_data])\n",
        "    labels = np.array([entry.labels[0].category for entry in source_data])\n",
        "    \n",
        "    # Calculate current and target distributions\n",
        "    n_categories = len(target_distribution)\n",
        "    current_counts = np.array([np.sum(labels == i) for i in range(n_categories)])\n",
        "    current_dist = current_counts / len(labels)\n",
        "    \n",
        "    # Calculate number of samples needed for each category\n",
        "    target_size = len(labels)\n",
        "    target_counts = (target_distribution * target_size).astype(int)\n",
        "    \n",
        "    # Initialize arrays for balanced dataset\n",
        "    balanced_images = []\n",
        "    balanced_labels = []\n",
        "    \n",
        "    # Resample each category\n",
        "    for category in range(n_categories):\n",
        "        category_indices = np.where(labels == category)[0]\n",
        "        \n",
        "        # If we need more samples than available, sample with replacement\n",
        "        if target_counts[category] > len(category_indices):\n",
        "            sampled_indices = np.random.choice(\n",
        "                category_indices,\n",
        "                size=target_counts[category],\n",
        "                replace=True\n",
        "            )\n",
        "        # If we need fewer samples, sample without replacement\n",
        "        else:\n",
        "            sampled_indices = np.random.choice(\n",
        "                category_indices,\n",
        "                size=target_counts[category],\n",
        "                replace=False\n",
        "            )\n",
        "            \n",
        "        balanced_images.extend(images[sampled_indices])\n",
        "        balanced_labels.extend(labels[sampled_indices])\n",
        "    \n",
        "    # Convert to numpy arrays and shuffle\n",
        "    balanced_images = np.array(balanced_images)\n",
        "    balanced_labels = np.array(balanced_labels)\n",
        "    \n",
        "    # Shuffle the balanced dataset\n",
        "    shuffle_idx = np.random.permutation(len(balanced_images))\n",
        "    balanced_images = balanced_images[shuffle_idx]\n",
        "    balanced_labels = balanced_labels[shuffle_idx]\n",
        "    \n",
        "    return balanced_images, balanced_labels\n",
        "\n",
        "# Calculate target distribution from training data\n",
        "train_images, train_labels = get_data(train_data)\n",
        "target_distribution = np.array([np.sum(train_labels == i) for i in range(len(categories))]) / len(train_labels)\n",
        "\n",
        "# Resample validation and test data to match training distribution\n",
        "validate_images, validate_labels = get_balanced_data(validate_data, target_distribution)\n",
        "test_images, test_labels = get_balanced_data(test_data, target_distribution)\n",
        "\n",
        "# Print distributions to verify\n",
        "print(f'Category distribution in the training dataset ({len(train_images)} images):')\n",
        "print_category_distribution(train_labels)\n",
        "print(f'Category distribution in the validation dataset ({len(validate_images)} images):')\n",
        "print_category_distribution(validate_labels)\n",
        "print(f'Category distribution in the test dataset ({len(test_images)} images):')\n",
        "print_category_distribution(test_labels)\n",
        "\n",
        "# test_images, test_labels = get_data(test_data)\n",
        "# validate_images, validate_labels = get_data(validate_data)\n",
        "# train_images, train_labels = get_data(train_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MLP Training\n",
        "Summary: Overfitting horror, kept adding more dropout and regularization & simplifying network but still experiencing horrendous overfitting. Then changed the image resolution from 64x64 to 32x32 and min_bounding_box_size from 0.3 to 0.5 and now the model performs okay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(img_size, img_size, 3)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(len(categories), activation='softmax'))\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "            train_images,\n",
        "            train_labels,\n",
        "            batch_size=32,\n",
        "            epochs=120,\n",
        "            validation_data=(validate_images, validate_labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CNN Training\n",
        "Yesss! 90% val accuracy (still slight overfitting)\n",
        "Idk if my network is too complex, it's inspired by a model for 43 different traffic signs, I reduced the layer sizes and increased regularization & dropout. BatchNormalization made the learning curve look weird."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Dropout, AveragePooling2D, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Create model\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(img_size, img_size, 3)))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(categories), activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, \n",
        "                    train_labels, \n",
        "                    epochs=60,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(validate_images, validate_labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Loading\n",
        "Skip the training process above and instantly load a keras model from disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.saving import load_model\n",
        "model = load_model('models/model_name.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], color='red', label='Training')\n",
        "plt.plot(history.history['val_accuracy'], color='blue', label='Validierung')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochen')\n",
        "plt.ylabel('Genauigkeit')\n",
        "# plt.savefig('images/cnn_training.png')\n",
        "# model.save('models/model_name.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Visualization\n",
        "Displays each layer, filter and output with matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def reshape_to_aspect(arr, aspect_ratio):\n",
        "    \"\"\"\n",
        "    Reshapes a 1D numpy array into a 2D grid that best matches the desired aspect ratio.\n",
        "    Adds padding (zeros) if necessary to fill the grid.\n",
        "    \n",
        "    Parameters:\n",
        "    arr (numpy.ndarray): 1D input array.\n",
        "    aspect_ratio (tuple): Desired aspect ratio as (width, height).\n",
        "    \n",
        "    Returns:\n",
        "    numpy.ndarray: 2D reshaped array with padding if necessary.\n",
        "    \"\"\"\n",
        "    if arr.size == 0:\n",
        "        return np.zeros((0, 0))\n",
        "    \n",
        "    w, h = aspect_ratio\n",
        "    target_ratio = w / h\n",
        "    N = arr.size\n",
        "    \n",
        "    # Calculate ideal number of rows based on target ratio\n",
        "    rows_ideal = np.sqrt(N / target_ratio)\n",
        "    \n",
        "    # Determine the range of rows to check around the ideal value\n",
        "    min_row = max(1, int(np.floor(rows_ideal)) - 3)\n",
        "    max_row = int(np.ceil(rows_ideal)) + 3\n",
        "    \n",
        "    best_diff = float('inf')\n",
        "    best_pad = float('inf')\n",
        "    best_shape = (1, N)  # Default shape, will be updated\n",
        "    \n",
        "    for row in range(min_row, max_row + 1):\n",
        "        if row == 0:\n",
        "            continue\n",
        "        cols = (N + row - 1) // row  # Ceiling division\n",
        "        actual_ratio = cols / row\n",
        "        ratio_diff = abs(actual_ratio - target_ratio)\n",
        "        padding = row * cols - N\n",
        "        \n",
        "        # Update best candidate if current is better\n",
        "        if (ratio_diff < best_diff) or (ratio_diff == best_diff and padding < best_pad):\n",
        "            best_diff = ratio_diff\n",
        "            best_pad = padding\n",
        "            best_shape = (row, cols)\n",
        "    \n",
        "    # Pad the array with zeros to fit the desired shape\n",
        "    padded = np.pad(arr, (0, best_shape[0] * best_shape[1] - N), mode='constant')\n",
        "    \n",
        "    return padded.reshape(best_shape)\n",
        "\n",
        "def save_model_layer_images(test_image, save_path='images/model'):\n",
        "    print(f'Saving model layers as images in {save_path}...')\n",
        "\n",
        "    if os.path.exists(save_path):\n",
        "        shutil.rmtree(save_path)\n",
        "    \n",
        "    os.mkdir(save_path)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(test_image[0])\n",
        "    plt.axis('off')\n",
        "    plt.savefig(os.path.join(save_path, 'input_image.png'), bbox_inches='tight')\n",
        "    plt.clf()\n",
        "\n",
        "    for i, layer in enumerate(model.layers):\n",
        "        layer_visible = False\n",
        "\n",
        "        if isinstance(layer, Conv2D):\n",
        "            layer_visible = True\n",
        "            output = Sequential(layers=model.layers[:i+1]).predict(test_image, verbose=0)\n",
        "            filters = layer.get_weights()[0]\n",
        "            n_filters = filters.shape[3]\n",
        "            \n",
        "            height = 20\n",
        "            fig, axs = plt.subplots(n_filters, 2, figsize=(height / n_filters * 2 + 1, height))\n",
        "            \n",
        "            # axs[0, 0].set_title(f'Gewichte')\n",
        "            for j in range(n_filters):\n",
        "                filter_viz = np.mean(filters[:, :, :, j-1], axis=2)\n",
        "                axs[j, 0].imshow(filter_viz, cmap='gray')\n",
        "                axs[j, 0].axis('off')\n",
        "            \n",
        "            # axs[0, 1].set_title(f'Output')\n",
        "            for j in range(n_filters):\n",
        "                axs[j, 1].imshow(output[0, :, :, j], cmap='gray')\n",
        "                axs[j, 1].axis('off')\n",
        "            \n",
        "            plt.subplots_adjust(wspace=0, hspace=0)\n",
        "            plt.tight_layout(h_pad=height / n_filters * 0.5)\n",
        "            \n",
        "        elif isinstance(layer, (MaxPooling2D, AveragePooling2D)):\n",
        "            layer_visible = True\n",
        "            output = Sequential(layers=model.layers[:i+1]).predict(test_image, verbose=0)\n",
        "            n_outputs = output.shape[-1]\n",
        "            \n",
        "            height = 20\n",
        "            fig, axs = plt.subplots(n_outputs, 1, figsize=(height / n_outputs * 2, height))\n",
        "            \n",
        "            for j in range(n_outputs):\n",
        "                axs[j].imshow(output[0, :, :, j], cmap='gray' if output.shape[-1] != 3 else ['Reds', 'Greens', 'Blues'][j])\n",
        "                axs[j].axis('off')\n",
        "            \n",
        "            plt.tight_layout(h_pad=height / n_outputs * 0.5)\n",
        "        \n",
        "        elif i == len(model.layers) - 1:\n",
        "            layer_visible = True\n",
        "            output = Sequential(layers=model.layers[:i+1]).predict(test_image, verbose=0)\n",
        "            fig, ax = plt.subplots(1, 1, figsize=(2, 8))\n",
        "            ax.barh(np.arange(len(output[0])), output[0])\n",
        "            ax.set_yticks(np.arange(len(output[0])))\n",
        "            ax.set_yticklabels([categories[i].replace('Speed ', '') for i in range(len(output[0]))], rotation=45, ha='right')\n",
        "            plt.tight_layout()\n",
        "            \n",
        "        elif isinstance(layer, Dense):\n",
        "            layer_visible = True\n",
        "            output = Sequential(layers=model.layers[:i+1]).predict(test_image, verbose=0)\n",
        "            image = reshape_to_aspect(output[0], (1, len(output[0]) // 2))\n",
        "            fig, ax = plt.subplots(figsize=(2, 20))\n",
        "            plt.axis('off')\n",
        "            plt.imshow(image, cmap='gray')\n",
        "        \n",
        "        if layer_visible:\n",
        "            plt.savefig(os.path.join(save_path, f'layer_{i}'), bbox_inches='tight')\n",
        "            plt.clf()\n",
        "    \n",
        "    print(f'Saved model layers as images in {save_path}!')\n",
        "\n",
        "def plot_model_from_saved_images(save_path='images/model'):\n",
        "    visible_layers = [(i, layer) for i, layer in enumerate(model.layers) \n",
        "                  if isinstance(layer, (MaxPooling2D, AveragePooling2D, Conv2D, Dense))]\n",
        "\n",
        "    fig, ax = plt.subplots(1, len(visible_layers) + 1, figsize=(20, 15))\n",
        "    ax[0].imshow(plt.imread(os.path.join(save_path, 'input_image.png')))\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    for j, (i, layer) in enumerate(visible_layers):\n",
        "        ax[j + 1].imshow(plt.imread(os.path.join(save_path, f'layer_{i}.png')))\n",
        "        ax[j + 1].axis('off')\n",
        "\n",
        "        if isinstance(layer, Conv2D):\n",
        "           pass\n",
        "            \n",
        "        elif isinstance(layer, (MaxPooling2D, AveragePooling2D)):\n",
        "            pass\n",
        "        \n",
        "        elif i == len(model.layers) - 1:\n",
        "            pass\n",
        "            \n",
        "        elif isinstance(layer, Dense):\n",
        "            pass\n",
        "    \n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    plt.tight_layout(pad=0)\n",
        "    plt.show()\n",
        "            \n",
        "    \n",
        "def plot_model(test_image):\n",
        "    clear_output(wait=True)\n",
        "    print(model.summary())\n",
        "    save_model_layer_images(test_image)\n",
        "    plot_model_from_saved_images()\n",
        "    \n",
        "\n",
        "\n",
        "# find images from validation set that are misclassified\n",
        "# misclassified = []\n",
        "# for i, (image, label) in enumerate(zip(validate_images, validate_labels)):\n",
        "#     prediction = model.predict(image[np.newaxis, ...])\n",
        "#     predicted_label = np.argmax(prediction)\n",
        "#     if predicted_label != label or True:\n",
        "#         misclassified.append((image, label, predicted_label))\n",
        "#         visualize_model(np.array([image]))\n",
        "#         break\n",
        "#         input('Weiter mit Enter')\n",
        "\n",
        "stop_signs = [entry for entry in validate_data if entry.labels[0].category == 14]\n",
        "test_image = np.array([stop_signs[8].image])\n",
        "\n",
        "plot_model(test_image)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example predictions\n",
        "Show the model's guesses on different images from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "only_misclassified = True\n",
        "skipped = 0\n",
        "for entry in validate_data:\n",
        "    label = model.predict(np.array([entry.image]), verbose=0)[0].argmax()\n",
        "    if label == entry.labels[0].category and only_misclassified:\n",
        "        skipped += 1\n",
        "        continue\n",
        "    \n",
        "    if only_misclassified:\n",
        "        print(f'Skipped: {skipped} correctly classified images')\n",
        "        skipped = 0\n",
        "    \n",
        "    plt.imshow(entry.image, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Predicted: {categories[label]}, Actual: {categories[entry.labels[0].category]}')\n",
        "    plt.show()\n",
        "    input('Press enter to continue...')\n",
        "    clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "___\n",
        "## Image Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_filter(image: np.array, filter: np.array, stride: int = 1)->np.array:\n",
        "    image_copy = deepcopy(image)\n",
        "    filter_size = filter.shape[0]\n",
        "    image_size = image.shape[0]\n",
        "    for i in range(0, image_size - filter_size + 1, stride):\n",
        "        for j in range(0, image_size - filter_size + 1, stride):\n",
        "            image[i:i + filter_size, j:j + filter_size] = (image_copy[i:i + filter_size, j:j + filter_size] * filter).sum()\n",
        "    \n",
        "    return image\n",
        "\n",
        "\n",
        "stop_signs = [entry for entry in validate_data if entry.labels[0].category == 14]\n",
        "grayscale_img = np.array(stop_signs[8].image).sum(axis=2) / 3\n",
        "vertical_edge_filter = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]])\n",
        "horizontal_edge_filter = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]])\n",
        "laplace_edge_filter = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]])\n",
        "\n",
        "plt.axis('off')\n",
        "plt.imshow(grayscale_img, cmap='gray')\n",
        "# plt.imsave('images/Stoppschild_laplace.png', grayscale_img, cmap='gray')\n",
        "\n",
        "horizontal = apply_filter(deepcopy(grayscale_img),  horizontal_edge_filter, stride=1)\n",
        "laplace = apply_filter(deepcopy(grayscale_img), laplace_edge_filter, stride=1)\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axs[0].imshow(horizontal, cmap='gray')\n",
        "axs[0].axis('off')\n",
        "axs[0].set_title('Horizontale Kanten')\n",
        "\n",
        "axs[1].imshow(laplace, cmap='gray')\n",
        "axs[1].axis('off')\n",
        "axs[1].set_title('Laplace-Filter')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Show how an image is made out of numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stop_signs = [entry for entry in validate_data if entry.labels[0].category == 14]\n",
        "\n",
        "size = 14\n",
        "grayscale_img = np.array(stop_signs[8].image).sum(axis=2) / 3\n",
        "scaled_img = np.array(Image.fromarray(grayscale_img).resize((size, size)))\n",
        "fig, axs = plt.subplots(1, 3, figsize=(16, 8))\n",
        "axs[0].imshow(grayscale_img, cmap='gray')\n",
        "axs[0].axis('off')\n",
        "axs[0].set_title('Original (Schwarz-WeiÃŸ)')\n",
        "\n",
        "axs[1].imshow(scaled_img, cmap='gray')\n",
        "axs[1].axis('off')\n",
        "axs[1].set_title('Skaliert auf 14x14 Pixel')\n",
        "\n",
        "axs[2].imshow(scaled_img, cmap='gray')\n",
        "axs[2].axis('off')\n",
        "axs[2].set_title('Helligkeitswerte')\n",
        "\n",
        "for i in range(size):\n",
        "    for j in range(size):\n",
        "        axs[2].text(j, i, f'{scaled_img[i, j]:.2f}', ha='center', va='center', color='black' if scaled_img[i, j] > 0.5 else 'white', fontsize=7)\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
