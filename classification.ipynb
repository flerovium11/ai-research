{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train different Neural Networks on a Traffic Sign Detection Dataset\n",
        "https://cs231n.github.io/neural-networks-3/#sanitycheck\\\n",
        "https://www.analyticsvidhya.com/blog/2021/12/traffic-signs-recognition-using-cnn-and-keras-in-python/#h-cnn-model-building\\\n",
        "https://medium.com/towards-data-science/8-simple-techniques-to-prevent-overfitting-4d443da2ef7d\\\n",
        "https://www.youtube.com/watch?v=r0RspiLG260\\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# global imports\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "dataset_path = 'data/GTSRB'\n",
        "classes_path = os.path.join(dataset_path, 'classes.txt')\n",
        "classes_german_path = os.path.join(dataset_path, 'classes-german.txt')\n",
        "img_size = 32\n",
        "\n",
        "with open(classes_path, 'r') as file:\n",
        "    classes = [line.strip() for line in file.readlines()]\n",
        "\n",
        "with open(classes_german_path, 'r', encoding='utf-8') as file:\n",
        "    classes_german = [line.strip() for line in file.readlines()]\n",
        "\n",
        "images_path = os.path.join(dataset_path, 'Training')\n",
        "class_folders = [folder for folder in os.listdir(images_path) if os.path.isdir(os.path.join(images_path, folder))]\n",
        "data = []\n",
        "\n",
        "for i, folder in enumerate(class_folders):\n",
        "    folder_path = os.path.join(images_path, folder)\n",
        "    files = glob.glob(os.path.join(folder_path, '*.ppm'))\n",
        "    label = int(folder)\n",
        "\n",
        "    for file in files:\n",
        "        image = plt.imread(file)\n",
        "        image = cv2.resize(image, (img_size, img_size))\n",
        "        data.append((image, label))\n",
        "\n",
        "print()\n",
        "print(f'Loaded {len(data)} images')\n",
        "\n",
        "print('Category distribution:')\n",
        "for i, class_name in enumerate(classes):\n",
        "    print(f'{class_name}: {len(list(filter(lambda entry: entry[1] == i, data)))}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Visualization\n",
        "Show random images from loaded data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_images = 6\n",
        "classes_to_display = [14, 12, 23, 36]\n",
        "fig, axs = plt.subplots(len(classes_to_display), num_images, figsize=(num_images * 2, len(classes_to_display) * 2))\n",
        "print(f'Displaying {num_images} random images from each of the following categories: {\", \".join([classes[class_num] for class_num in classes_to_display])}')\n",
        "\n",
        "for i, class_num in enumerate(classes_to_display):\n",
        "    class_images = [entry[0] for entry in data if entry[1] == class_num]\n",
        "    \n",
        "    if len(class_images) >= num_images:\n",
        "        selected_images = random.sample(class_images, num_images)\n",
        "    else:\n",
        "        selected_images = class_images\n",
        "    \n",
        "    for j, image in enumerate(selected_images):\n",
        "        axs[i, j].imshow(image, cmap='gray')\n",
        "        axs[i, j].axis('off')\n",
        "        if j == 0:\n",
        "            axs[i, j].set_title(classes_german[class_num])\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.axis('off')\n",
        "\n",
        "# plt.savefig('media/Datenset_Auszug.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "split_train_val = 0.8\n",
        "split_index = int(len(data) * split_train_val)\n",
        "np.random.shuffle(data)\n",
        "train_data, val_data = data[:split_index], data[split_index:]\n",
        "train_images, train_labels = np.array([entry[0] for entry in train_data]), np.array([entry[1] for entry in train_data])\n",
        "val_images, val_labels = np.array([entry[0] for entry in val_data]), np.array([entry[1] for entry in val_data])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### MLP Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(img_size, img_size, 3)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(len(classes), activation='softmax'))\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "            train_images,\n",
        "            train_labels,\n",
        "            batch_size=128,\n",
        "            epochs=75,\n",
        "            validation_data=(val_images, val_labels))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CNN Training\n",
        "Yesss! 98% val accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Dropout, AveragePooling2D, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 32 (3, 3) 512 0.1 0.3 256 -> 0.981\n",
        "# 32 (3, 3) 512 0.25 0.2 256 -> 0.980\n",
        "# 64 (3, 3) 128 0.25 0.1 128 -> 0.981\n",
        "# 32 (3, 3) 512 0.3 0.1 256 -> 0.979\n",
        "# 32 (3, 3) 256 0.2 0.2 256 -> 0.979\n",
        "# 32 (3, 3) 512 0 0.5 64 -> 0.978\n",
        "# 32 (3, 3) 512 0.2 0.4 256 -> 0.979\n",
        "# 32 (3, 3) 512 0.35 0.2 256 -> 0.978\n",
        "# 64 (3, 3) 256 0.1 0.1 256 -> 0.978\n",
        "# 64 (3, 3) 256 0.1 0.2 128 -> 0.979\n",
        "# 64 (3, 3) 256 0.25 0.3 256 -> 0.979\n",
        "# best: 32 (3, 3) 512 0.25 0.2 256\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(img_size, img_size, 3)))\n",
        "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(8, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(len(classes), activation='softmax'))\n",
        "model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, \n",
        "    train_labels, \n",
        "    epochs=10,\n",
        "    batch_size=256,\n",
        "    validation_data=(val_images, val_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Loading\n",
        "Skip the training process above and instantly load a keras model from disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.saving import load_model\n",
        "model = load_model('models/cnn_gtsrb_98_val_acc.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(val_images, val_labels)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], color='red', label='Training')\n",
        "plt.plot(history.history['val_accuracy'], color='blue', label='Validierung')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochen')\n",
        "plt.gca().xaxis.set_major_locator(matplotlib.ticker.MaxNLocator(integer=True))\n",
        "plt.ylabel('Genauigkeit')\n",
        "# plt.savefig('media/CNN_Training_Diagramm.png')\n",
        "# model.save('models/cnn_gtsrb_98_val_acc.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = model.predict(train_images)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "conf_matrix = np.zeros((len(classes), len(classes)), dtype=int)\n",
        "\n",
        "for true, prediction in zip(train_labels, predicted_labels):\n",
        "    conf_matrix[true, prediction] += 1\n",
        "\n",
        "missclassifications = np.sum(conf_matrix, axis=1) - np.diag(conf_matrix)\n",
        "worst_classes = np.argsort(missclassifications)[-10:]\n",
        "\n",
        "sub_matrix = conf_matrix[np.ix_(worst_classes, worst_classes)]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "cax = ax.matshow(sub_matrix, cmap='Blues', norm=matplotlib.colors.LogNorm())\n",
        "# cbar = plt.colorbar(cax, ticks=[1, 10, 100])\n",
        "# cbar.ax.set_yticklabels(['0', '10', '100'])\n",
        "\n",
        "ax.set_xticks(range(len(worst_classes)))\n",
        "ax.set_yticks(range(len(worst_classes)))\n",
        "ax.set_xticklabels([classes_german[class_num] for class_num in worst_classes])\n",
        "ax.set_yticklabels([classes_german[class_num] for class_num in worst_classes])\n",
        "ax.xaxis.set_label_position('bottom')\n",
        "ax.xaxis.tick_bottom()\n",
        "for x, row in enumerate(sub_matrix):\n",
        "    for y, val in enumerate(row):\n",
        "        ax.text(y, x, f'{val}', ha='center', va='center', color='black' if val < np.max(sub_matrix) / 2 else 'white', fontsize=7)\n",
        "\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.xlabel('Vorhersage')\n",
        "plt.ylabel('Richtiger Wert')\n",
        "plt.title('Konfusionsmatrix: 10 am meisten verwechselte Schilder', pad=20)\n",
        "# plt.savefig('media/CNN_Konfusionsmatrix.png', bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\\n'.join([f'{i}: {classes_german[label]}' for i, label in enumerate(train_labels)]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Visualization\n",
        "Displays each layer, filter and output with matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "from tensorflow.keras.layers import Conv2D, Dense, AveragePooling2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def reshape_to_aspect(arr, aspect_ratio):\n",
        "    \"\"\"\n",
        "    Reshapes a 1D numpy array into a 2D grid that best matches the desired aspect ratio.\n",
        "    Adds padding (zeros) if necessary to fill the grid.\n",
        "    \n",
        "    Parameters:\n",
        "    arr (numpy.ndarray): 1D input array.\n",
        "    aspect_ratio (tuple): Desired aspect ratio as (width, height).\n",
        "    \n",
        "    Returns:\n",
        "    numpy.ndarray: 2D reshaped array with padding if necessary.\n",
        "    \"\"\"\n",
        "    if arr.size == 0:\n",
        "        return np.zeros((0, 0))\n",
        "    \n",
        "    w, h = aspect_ratio\n",
        "    target_ratio = w / h\n",
        "    N = arr.size\n",
        "    \n",
        "    # Calculate ideal number of rows based on target ratio\n",
        "    rows_ideal = np.sqrt(N / target_ratio)\n",
        "    \n",
        "    # Determine the range of rows to check around the ideal value\n",
        "    min_row = max(1, int(np.floor(rows_ideal)) - 3)\n",
        "    max_row = int(np.ceil(rows_ideal)) + 3\n",
        "    \n",
        "    best_diff = float('inf')\n",
        "    best_pad = float('inf')\n",
        "    best_shape = (1, N)  # Default shape, will be updated\n",
        "    \n",
        "    for row in range(min_row, max_row + 1):\n",
        "        if row == 0:\n",
        "            continue\n",
        "        cols = (N + row - 1) // row  # Ceiling division\n",
        "        actual_ratio = cols / row\n",
        "        ratio_diff = abs(actual_ratio - target_ratio)\n",
        "        padding = row * cols - N\n",
        "        \n",
        "        # Update best candidate if current is better\n",
        "        if (ratio_diff < best_diff) or (ratio_diff == best_diff and padding < best_pad):\n",
        "            best_diff = ratio_diff\n",
        "            best_pad = padding\n",
        "            best_shape = (row, cols)\n",
        "    \n",
        "    # Pad the array with zeros to fit the desired shape\n",
        "    padded = np.pad(arr, (0, best_shape[0] * best_shape[1] - N), mode='constant')\n",
        "    \n",
        "    return padded.reshape(best_shape)\n",
        "\n",
        "def save_model_layer_images(test_image, save_path='media/model'):\n",
        "    print(f'Saving model layers as images in {save_path}...')\n",
        "\n",
        "    if os.path.exists(save_path):\n",
        "        shutil.rmtree(save_path)\n",
        "    \n",
        "    os.mkdir(save_path)\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(test_image)\n",
        "    plt.axis('off')\n",
        "    plt.savefig(os.path.join(save_path, 'input_image.png'), bbox_inches='tight')\n",
        "    plt.clf()\n",
        "\n",
        "    for i, layer in enumerate(model.layers):\n",
        "        layer_visible = False\n",
        "        output = Sequential(layers=model.layers[:i+1]).predict(np.expand_dims(test_image, axis=0), verbose=0)\n",
        "\n",
        "        if isinstance(layer, Conv2D):\n",
        "            layer_visible = True\n",
        "            filters = layer.get_weights()[0]\n",
        "            n_filters = filters.shape[3]\n",
        "            \n",
        "            height = 20\n",
        "            fig, axs = plt.subplots(n_filters, 2, figsize=(height / n_filters * 2 + 1, height))\n",
        "            \n",
        "            # axs[0, 0].set_title(f'Gewichte')\n",
        "            for j in range(n_filters):\n",
        "                filter_viz = np.mean(filters[:, :, :, j-1], axis=2)\n",
        "                axs[j, 0].imshow(filter_viz, cmap='gray')\n",
        "                axs[j, 0].axis('off')\n",
        "            \n",
        "            # axs[0, 1].set_title(f'Output')\n",
        "            for j in range(n_filters):\n",
        "                axs[j, 1].imshow(output[0, :, :, j], cmap='gray')\n",
        "                axs[j, 1].axis('off')\n",
        "            \n",
        "            plt.subplots_adjust(wspace=0, hspace=0)\n",
        "            plt.tight_layout(h_pad=height / n_filters * 0.5)\n",
        "            \n",
        "        elif isinstance(layer, (MaxPooling2D, AveragePooling2D)):\n",
        "            layer_visible = True\n",
        "            n_outputs = output.shape[-1]\n",
        "            \n",
        "            height = 20\n",
        "            fig, axs = plt.subplots(n_outputs, 1, figsize=(height / n_outputs * 2, height))\n",
        "            \n",
        "            for j in range(n_outputs):\n",
        "                axs[j].imshow(output[0, :, :, j], cmap='gray' if output.shape[-1] != 3 else ['Reds', 'Greens', 'Blues'][j])\n",
        "                axs[j].axis('off')\n",
        "            \n",
        "            plt.tight_layout(h_pad=height / n_outputs * 0.5)\n",
        "        \n",
        "        elif i == len(model.layers) - 1:\n",
        "            layer_visible = True\n",
        "            fig, ax = plt.subplots(1, 1, figsize=(2.5, 10))\n",
        "            ax.barh(np.arange(len(output[0])), output[0])\n",
        "            ax.set_yticks(np.arange(len(output[0])))\n",
        "            ax.set_yticklabels([classes_german[i] for i in range(len(output[0]))], rotation=45, ha='right')\n",
        "            plt.tight_layout()\n",
        "            \n",
        "        elif isinstance(layer, Dense):\n",
        "            layer_visible = True\n",
        "            image = reshape_to_aspect(output[0], (1, len(output[0]) // 2))\n",
        "            fig, ax = plt.subplots(figsize=(2, 20))\n",
        "            plt.axis('off')\n",
        "            plt.imshow(image, cmap='gray')\n",
        "        \n",
        "        if layer_visible:\n",
        "            plt.savefig(os.path.join(save_path, f'layer_{i}'), bbox_inches='tight')\n",
        "            plt.clf()\n",
        "    \n",
        "    print(f'Saved model layers as images in {save_path}!')\n",
        "\n",
        "def plot_model_from_saved_images(save_path='media/model'):\n",
        "    visible_layers = [(i, layer) for i, layer in enumerate(model.layers) \n",
        "                  if isinstance(layer, (MaxPooling2D, AveragePooling2D, Conv2D, Dense))]\n",
        "\n",
        "    fig, ax = plt.subplots(1, len(visible_layers) + 1, figsize=(20, 15))\n",
        "    ax[0].imshow(plt.imread(os.path.join(save_path, 'input_image.png')))\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    for j, (i, layer) in enumerate(visible_layers):\n",
        "        ax[j + 1].imshow(plt.imread(os.path.join(save_path, f'layer_{i}.png')))\n",
        "        ax[j + 1].axis('off')\n",
        "\n",
        "        if isinstance(layer, Conv2D):\n",
        "           pass\n",
        "            \n",
        "        elif isinstance(layer, (MaxPooling2D, AveragePooling2D)):\n",
        "            pass\n",
        "        \n",
        "        elif i == len(model.layers) - 1:\n",
        "            pass\n",
        "            \n",
        "        elif isinstance(layer, Dense):\n",
        "            pass\n",
        "    \n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    plt.tight_layout(pad=0)\n",
        "    plt.show()\n",
        "            \n",
        "    \n",
        "def plot_model(test_image):\n",
        "    clear_output(wait=True)\n",
        "    print(model.summary())\n",
        "    save_model_layer_images(test_image)\n",
        "    plot_model_from_saved_images()\n",
        "\n",
        "test_image = train_images[16351]\n",
        "\n",
        "plot_model(test_image)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example predictions\n",
        "Show the model's guesses on different images from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "only_misclassified = True\n",
        "skipped = 0\n",
        "n, m = 3, 3\n",
        "figsize = (m * 3, n * 3)\n",
        "\n",
        "misclassified = []\n",
        "predictions = model.predict(train_images)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "for true, prediction, image in zip(train_labels, predicted_labels, train_images):\n",
        "    if true == prediction and only_misclassified:\n",
        "        skipped += 1\n",
        "        continue\n",
        "\n",
        "    misclassified.append((image, true, prediction))\n",
        "\n",
        "    if len(misclassified) == n * m:\n",
        "        print(f'Skipped: {skipped} correctly classified images')\n",
        "        skipped = 0\n",
        "        \n",
        "        fig, axes = plt.subplots(n, m, figsize=figsize)\n",
        "        axes = axes.ravel()\n",
        "        \n",
        "        for i, (img, true_label, pred_label) in enumerate(misclassified):\n",
        "            axes[i].imshow(img, cmap='gray')\n",
        "            axes[i].axis('off')\n",
        "            axes[i].set_title(f'{classes_german[true_label]} ({classes_german[pred_label]})')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        # plt.savefig('media/temp.png')\n",
        "        plt.show()\n",
        "        user_input = input('Press enter and type \"exit\" to exit...')\n",
        "        if user_input == 'exit':\n",
        "            # os.rename('media/temp.png', 'media/CNN_Falsche_Vorhersagen.png')\n",
        "            break\n",
        "        \n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        misclassified = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "___\n",
        "## Image Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def apply_filter(image: np.array, filter: np.array, stride: int = 1)->np.array:\n",
        "    image_copy = deepcopy(image)\n",
        "    filter_size = filter.shape[0]\n",
        "    image_size = image.shape[0]\n",
        "    for i in range(0, image_size - filter_size + 1, stride):\n",
        "        for j in range(0, image_size - filter_size + 1, stride):\n",
        "            image[i:i + filter_size, j:j + filter_size] = (image_copy[i:i + filter_size, j:j + filter_size] * filter).sum()\n",
        "    \n",
        "    return image\n",
        "\n",
        "\n",
        "stop_signs = [entry for entry in validate_data if entry.labels[0].category == 14]\n",
        "grayscale_img = np.array(stop_signs[8].image).sum(axis=2) / 3\n",
        "vertical_edge_filter = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]])\n",
        "horizontal_edge_filter = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]])\n",
        "laplace_edge_filter = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]])\n",
        "\n",
        "plt.axis('off')\n",
        "plt.imshow(grayscale_img, cmap='gray')\n",
        "# plt.imsave('media/Stoppschild_laplace.png', grayscale_img, cmap='gray')\n",
        "\n",
        "horizontal = apply_filter(deepcopy(grayscale_img),  horizontal_edge_filter, stride=1)\n",
        "laplace = apply_filter(deepcopy(grayscale_img), laplace_edge_filter, stride=1)\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axs[0].imshow(horizontal, cmap='gray')\n",
        "axs[0].axis('off')\n",
        "axs[0].set_title('Horizontale Kanten')\n",
        "\n",
        "axs[1].imshow(laplace, cmap='gray')\n",
        "axs[1].axis('off')\n",
        "axs[1].set_title('Laplace-Filter')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Show how an image is made out of numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stop_signs = [entry for entry in validate_data if entry.labels[0].category == 14]\n",
        "\n",
        "size = 14\n",
        "grayscale_img = np.array(stop_signs[8].image).sum(axis=2) / 3\n",
        "scaled_img = np.array(Image.fromarray(grayscale_img).resize((size, size)))\n",
        "fig, axs = plt.subplots(1, 3, figsize=(16, 8))\n",
        "axs[0].imshow(grayscale_img, cmap='gray')\n",
        "axs[0].axis('off')\n",
        "axs[0].set_title('Original (Schwarz-WeiÃŸ)')\n",
        "\n",
        "axs[1].imshow(scaled_img, cmap='gray')\n",
        "axs[1].axis('off')\n",
        "axs[1].set_title('Skaliert auf 14x14 Pixel')\n",
        "\n",
        "axs[2].imshow(scaled_img, cmap='gray')\n",
        "axs[2].axis('off')\n",
        "axs[2].set_title('Helligkeitswerte')\n",
        "\n",
        "for i in range(size):\n",
        "    for j in range(size):\n",
        "        axs[2].text(j, i, f'{scaled_img[i, j]:.2f}', ha='center', va='center', color='black' if scaled_img[i, j] > 0.5 else 'white', fontsize=7)\n",
        "\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
